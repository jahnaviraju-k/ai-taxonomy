{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "910bf71b",
   "metadata": {},
   "source": [
    "# Human-in-the-Loop (HITL): Algorithm's Interaction with Humans\n",
    "\n",
    "## Overview\n",
    "\n",
    "This document describes one of the six spheres from the Multidimensional Algorithm Structure (MAS) framework — **Human-in-the-Loop** — which explores how AI algorithms interact with humans within Human-Systems Integration (HSI) projects.\n",
    "\n",
    "In this dimension, we aim to clarify the **degree and type of human involvement** required by various algorithms. This classification supports more informed algorithm selection in contexts that demand transparency, explainability, and trust.\n",
    "\n",
    "---\n",
    "\n",
    "## HITL Interaction Types\n",
    "\n",
    "To enhance this dimension, we introduce a refined categorization of algorithm interaction styles with humans. These categories allow project teams to match algorithms to real-world HSI contexts more effectively.\n",
    "\n",
    "| Type        | Description                                                                 | Examples of Algorithms                          | Application Scenarios                         |\n",
    "|-------------|-----------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------|\n",
    "| **Direct**  | Human input is continuously required for operation or decision-making.       | Rule-based systems, Logistic Regression        | Clinical decision-making, control systems    |\n",
    "| **Indirect**| Human input is provided periodically, often as feedback or tuning signals.   | Reinforcement Learning (feedback), Active Learning | Industrial automation, education platforms |\n",
    "| **Opaque**  | Algorithm functions autonomously without user-facing explainability.         | Deep Neural Networks, CNNs, Black-box models   | Facial recognition, predictive policing      |\n",
    "| **Auto**    | Fully automated with embedded explainability or interpretability features.   | SHAP with XGBoost, LIME with Random Forest     | Autonomous driving, decision-support systems |\n",
    "\n",
    "---\n",
    "\n",
    "## Mapping HITL Levels to MAS and XAI Goals\n",
    "\n",
    "Each HITL interaction type plays a unique role in supporting Explainable AI (XAI) and Human-Systems Integration:\n",
    "\n",
    "- **Direct**: Best for critical domains where decisions must be justified in real time.\n",
    "- **Indirect**: Enables adaptive systems that learn from users while retaining autonomy.\n",
    "- **Opaque**: Often powerful but risky in safety-critical environments due to low transparency.\n",
    "- **Auto**: Ideal balance between autonomy and trust — crucial in industries like finance and healthcare.\n",
    "\n",
    "---\n",
    "\n",
    "## Contribution and Outcome\n",
    "\n",
    "In this project, I:\n",
    "- Designed the HITL dimension structure as part of the MAS framework\n",
    "- Classified algorithms by HITL interaction types to improve algorithm selection logic\n",
    "- Analyzed the role of HITL in increasing **trust** and **transparency** across **occupations** and **industries**\n",
    "- Identified patterns in when and why different HITL levels are required in HSI projects\n",
    "\n",
    "This framework strengthens the link between algorithm design and human-centered AI application goals, helping bridge the gap between usability, explainability, and technical performance.\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- O*NET Online Career Data – https://www.onetonline.org  \n",
    "- NAICS Industry Data – https://www.census.gov/naics/  \n",
    "- OpenML AI Algorithm Database – https://www.openml.org  \n",
    "- SHAP, LIME, XGBoost documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b402ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
